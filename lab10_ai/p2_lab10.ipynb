{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WF2cT_EeEXSq"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import math\n",
        "from scipy.stats import poisson\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "# maximum # of gbikes in each location\n",
        "MAX_GBIKE = 20\n",
        "\n",
        "MAX_MOVE_OF_GBIKE = 5\n",
        "\n",
        "RENTAL_REQUEST_FIRST_LOC = 3\n",
        "\n",
        "RENTAL_REQUEST_SECOND_LOC = 4\n",
        "\n",
        "RETURNS_FIRST_LOC = 3\n",
        "\n",
        "RETURNS_SECOND_LOC = 2\n",
        "\n",
        "GAMMA = 0.9\n",
        "\n",
        "RENTAL_CREDIT = 10\n",
        "\n",
        "MOVE_GBIKE_COST = 2\n",
        "\n",
        "# positive means first to second and negtaive means second to first \n",
        "actions = np.arange(-MAX_MOVE_OF_GBIKE, MAX_MOVE_OF_GBIKE + 1)\n",
        "\n",
        "POISSON_UPPER_BOUND = 11 # upper bound to poisson distribution\n",
        "\n",
        "value = np.zeros((MAX_GBIKE + 1, MAX_GBIKE + 1))\n",
        "policy = np.zeros(value.shape, dtype=np.int_)\n",
        "\n",
        "\n",
        "# backup or caching the poisson value because it may use next iteration\n",
        "\n",
        "pBackup = dict()"
      ],
      "metadata": {
        "id": "dMeLwntqEdJQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def poisson_dist(x, lam):\n",
        "    global pBackup\n",
        "    key = (x ,lam)\n",
        "    if key not in pBackup.keys():\n",
        "        pBackup[key] = poisson.pmf(x, lam)\n",
        "    return pBackup[key] \n",
        "\n",
        "def expected_return(state, action, state_value):\n",
        "    # cost for moving bikes\n",
        "    returns = float(-(MOVE_GBIKE_COST * abs(action)))\n",
        "\n",
        "    # moving gbike\n",
        "    NUM_OF_GBIKE_FIRST_LOC = int(max(min(state[0] - action, MAX_GBIKE),0))\n",
        "    NUM_OF_GBIKE_SECOND_LOC = int(max(min(state[1] + action, MAX_GBIKE),0))\n",
        "\n",
        "    # go through all possible rental requests\n",
        "    for rental_request_first_loc in range(POISSON_UPPER_BOUND):\n",
        "        for rental_request_second_loc in range(POISSON_UPPER_BOUND):\n",
        "            # probability for current combination of rental requests\n",
        "            prob = poisson_dist(rental_request_first_loc, RENTAL_REQUEST_FIRST_LOC) * poisson_dist(rental_request_second_loc, RENTAL_REQUEST_SECOND_LOC)\n",
        "\n",
        "            # valid rental requests should be less than actual # of gbike\n",
        "            valid_rental_first_loc = min(NUM_OF_GBIKE_FIRST_LOC, rental_request_first_loc)\n",
        "            valid_rental_second_loc = min(NUM_OF_GBIKE_SECOND_LOC, rental_request_second_loc)\n",
        "\n",
        "            # get credits for renting\n",
        "            reward = (valid_rental_first_loc + valid_rental_second_loc) * RENTAL_CREDIT\n",
        "            GBIKE_LOCATION_ONE = NUM_OF_GBIKE_FIRST_LOC - valid_rental_first_loc\n",
        "            GBIKE_LOCATION_TWO = NUM_OF_GBIKE_SECOND_LOC - valid_rental_second_loc\n",
        "\n",
        "            returned_location_one = RETURNS_FIRST_LOC\n",
        "            returned_location_two = RETURNS_SECOND_LOC\n",
        "            GBIKE_LOCATION_ONE = min(GBIKE_LOCATION_ONE + returned_location_one, MAX_GBIKE)\n",
        "            GBIKE_LOCATION_TWO = min(GBIKE_LOCATION_TWO + returned_location_two, MAX_GBIKE)\n",
        "            returns += prob * (reward + GAMMA * state_value[GBIKE_LOCATION_ONE, GBIKE_LOCATION_TWO])\n",
        "        return returns\n",
        "\n",
        "def policy_evaluation():\n",
        "    global value\n",
        "    while True:\n",
        "        old_value = value.copy()\n",
        "        for i in range(MAX_GBIKE + 1):\n",
        "            for j in range(MAX_GBIKE + 1):\n",
        "                new_state_value = expected_return([i, j], policy[i, j], value)\n",
        "                value[i, j] = new_state_value\n",
        "        max_value_change = abs(old_value - value).max()\n",
        "        print('max value change {}'.format(max_value_change))\n",
        "        if max_value_change < 1e-4:\n",
        "            break\n",
        "\n",
        "def policy_improvement():\n",
        "    global policy\n",
        "    policy_not_improvable = True\n",
        "    for i in range(MAX_GBIKE + 1):\n",
        "        for j in range(MAX_GBIKE + 1):\n",
        "            old_action = policy[i, j]\n",
        "            action_returns = []\n",
        "            for action in actions:\n",
        "                if (0 <= action <= i) or (-j <= action <= 0):\n",
        "                    action_returns.append(expected_return([i, j], action, value))\n",
        "                else:\n",
        "                    action_returns.append(-np.inf)\n",
        "            new_action = actions[np.argmax(action_returns)]\n",
        "            policy[i, j] = new_action\n",
        "            if policy_not_improvable and old_action != new_action:\n",
        "                policy_not_improvable = False\n",
        "    print('policy stable {}'.format(policy_not_improvable))\n",
        "\n",
        "    return policy_not_improvable\n",
        "\n",
        "\n",
        "def main():\n",
        "    iterations = 0\n",
        "    _, axes = plt.subplots(2, 3, figsize=(40, 20))\n",
        "    plt.subplots_adjust(wspace=0.1, hspace=0.2)\n",
        "    axes = axes.flatten()\n",
        "    while True:\n",
        "        fig = sns.heatmap(np.flipud(policy), cmap=\"YlGnBu\", ax=axes[iterations])\n",
        "        fig.set_ylabel('# gbike at first location', fontsize=30)\n",
        "        fig.set_yticks(list(reversed(range(MAX_GBIKE + 1))))\n",
        "        fig.set_xlabel('# gbike at second location', fontsize=30)\n",
        "        fig.set_title('policy {}'.format(iterations), fontsize=30)\n",
        "\n",
        "        # policy evaluation (in-place) No need to take other matrix for storing and saving \n",
        "        policy_evaluation()\n",
        "\n",
        "        # policy improvement\n",
        "        \n",
        "        policy_not_improvable = policy_improvement()\n",
        "\n",
        "        if policy_not_improvable:\n",
        "            # we got the optimal policy as nothing can be improved now and \n",
        "            fig = sns.heatmap(np.flipud(value), cmap=\"YlGnBu\", ax=axes[-1])\n",
        "            fig.set_ylabel('# gbike at first location', fontsize=30)\n",
        "            fig.set_yticks(list(reversed(range(MAX_GBIKE + 1))))\n",
        "            fig.set_xlabel('# gbike at second location', fontsize=30)\n",
        "            fig.set_title('optimal value', fontsize=30)\n",
        "            break\n",
        "\n",
        "        iterations += 1\n",
        "\n",
        "    plt.savefig('figure_gbike.png')\n",
        "    plt.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0JscCQUEkHV",
        "outputId": "79981a07-9207-40eb-e10a-d719727a29aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max value change 2.044835749152502\n",
            "max value change 0.09136462701597359\n",
            "max value change 0.004081349296944925\n",
            "max value change 0.0001818209987698438\n",
            "max value change 8.010231026034376e-06\n",
            "policy stable True\n"
          ]
        }
      ]
    }
  ]
}